# =============================================================================
# Model Deployment Workflow
# =============================================================================
# Deploys ML models from MLflow to KServe using kubectl directly.
# All secrets are read from Kubernetes secrets (deployed by Terraform).
# No sensitive values are passed via CLI or environment variables.
#
# Flow:
#   1. Verify model in Staging stage (MLflow)
#   2. Export model to ONNX (Kubernetes Job)
#   3. Deploy to staging KServe
#   4. Run smoke tests
#   5. Deploy to production (with approval)
# =============================================================================

name: Model Deploy

on:
  workflow_dispatch:
    inputs:
      model_name:
        description: 'Model name in MLflow registry'
        required: true
        default: 'spam-detector'
        type: string
      skip_export:
        description: 'Skip model export (use existing ONNX model)'
        required: false
        default: 'false'
        type: choice
        options:
          - 'false'
          - 'true'
      deploy_production:
        description: 'Deploy to production after staging'
        required: true
        default: 'true'
        type: choice
        options:
          - 'true'
          - 'false'

env:
  KSERVE_NAMESPACE: kserve
  SERVING_NAMESPACE: serving
  MLFLOW_NAMESPACE: mlflow
  # ACR name is fetched from cluster ConfigMap
  IMAGE_TAG: v0.35

jobs:
  # ===========================================================================
  # Step 1: Verify Model in Staging Stage
  # ===========================================================================
  verify-staging-model:
    name: Verify Model in Staging
    runs-on: ml-platform-runners
    
    outputs:
      version: ${{ steps.model-info.outputs.version }}
      run_id: ${{ steps.model-info.outputs.run_id }}
      acr_name: ${{ steps.cluster-info.outputs.acr_name }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/v1.28.0/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

      - name: Get Cluster Info
        id: cluster-info
        run: |
          # Get ACR name from kserve namespace configmap or secret
          ACR_NAME=$(kubectl get secret azure-storage-secret -n ${{ env.KSERVE_NAMESPACE }} \
            -o jsonpath='{.data.AZURE_STORAGE_ACCOUNT_NAME}' | base64 -d | sed 's/devsa/devacrqvwjyi.azurecr.io/' | sed 's/mltrainingsdevstqvwjyi/mltrainingsdevacrqvwjyi.azurecr.io/')
          
          # Fallback: hardcode if pattern doesn't match
          if [[ ! "$ACR_NAME" =~ "azurecr.io" ]]; then
            ACR_NAME="mltrainingsdevacrqvwjyi.azurecr.io"
          fi
          
          echo "acr_name=${ACR_NAME}" >> $GITHUB_OUTPUT
          echo "ðŸ“¦ ACR: ${ACR_NAME}"

      - name: Get Model in Staging Stage
        id: model-info
        run: |
          echo "ðŸ” Looking for model in Staging stage..."
          
          # Get MLflow service URL
          MLFLOW_URL="http://mlflow-service.${{ env.MLFLOW_NAMESPACE }}.svc.cluster.local:5000"
          
          # Query MLflow from within cluster
          RESPONSE=$(kubectl run mlflow-query-$(date +%s) \
            --image=curlimages/curl:latest \
            --restart=Never \
            --rm -i \
            --command -- curl -s "${MLFLOW_URL}/api/2.0/mlflow/registered-models/get-latest-versions" \
            -H "Content-Type: application/json" \
            -d '{"name": "${{ github.event.inputs.model_name }}", "stages": ["Staging"]}' 2>/dev/null || echo "{}")
          
          VERSION=$(echo "$RESPONSE" | grep -o '"version":"[^"]*"' | head -1 | cut -d'"' -f4)
          RUN_ID=$(echo "$RESPONSE" | grep -o '"run_id":"[^"]*"' | head -1 | cut -d'"' -f4)
          
          if [ -z "$VERSION" ]; then
            echo "âŒ No model found in Staging stage!"
            echo "   Please ensure the Kubeflow training pipeline has completed"
            exit 1
          fi
          
          echo "version=${VERSION}" >> $GITHUB_OUTPUT
          echo "run_id=${RUN_ID}" >> $GITHUB_OUTPUT
          
          echo "âœ… Found model version ${VERSION} in Staging stage"

      - name: Verification Summary
        run: |
          echo "## âœ… Model Verification" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Property | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Model | ${{ github.event.inputs.model_name }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Version | ${{ steps.model-info.outputs.version }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Stage | Staging |" >> $GITHUB_STEP_SUMMARY
          echo "| ACR | ${{ steps.cluster-info.outputs.acr_name }} |" >> $GITHUB_STEP_SUMMARY

  # ===========================================================================
  # Step 2: Export Model to ONNX (Kubernetes Job)
  # ===========================================================================
  export-model:
    name: Export Model to ONNX
    runs-on: ml-platform-runners
    needs: verify-staging-model
    if: github.event.inputs.skip_export != 'true'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/v1.28.0/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

      - name: Create and Run Export Job
        run: |
          TIMESTAMP=$(date +%s)
          JOB_NAME="model-export-${TIMESTAMP}"
          ACR_NAME="${{ needs.verify-staging-model.outputs.acr_name }}"
          
          echo "ðŸš€ Creating model export job: ${JOB_NAME}"
          
          # Create the job YAML with substitutions
          cat <<EOF | kubectl apply -f -
          apiVersion: batch/v1
          kind: Job
          metadata:
            name: ${JOB_NAME}
            namespace: ${{ env.KSERVE_NAMESPACE }}
            labels:
              app: model-export
              model-stage: Staging
          spec:
            ttlSecondsAfterFinished: 3600
            backoffLimit: 2
            template:
              metadata:
                labels:
                  app: model-export
              spec:
                restartPolicy: Never
                containers:
                  - name: model-export
                    image: ${ACR_NAME}/model-export:${{ env.IMAGE_TAG }}
                    args:
                      - "--model-name"
                      - "${{ github.event.inputs.model_name }}"
                      - "--model-stage"
                      - "Staging"
                    env:
                      - name: MLFLOW_TRACKING_URI
                        value: "http://mlflow-service.${{ env.MLFLOW_NAMESPACE }}.svc.cluster.local:5000"
                      - name: AZURE_STORAGE_ACCOUNT_NAME
                        valueFrom:
                          secretKeyRef:
                            name: azure-storage-secret
                            key: AZURE_STORAGE_ACCOUNT_NAME
                      - name: AZURE_STORAGE_ACCOUNT_KEY
                        valueFrom:
                          secretKeyRef:
                            name: azure-storage-secret
                            key: AZURE_STORAGE_ACCESS_KEY
                      - name: AZURE_STORAGE_CONTAINER
                        value: "models"
                    resources:
                      requests:
                        cpu: "500m"
                        memory: "1Gi"
                      limits:
                        cpu: "2"
                        memory: "4Gi"
          EOF
          
          # Wait for job to complete
          echo "â³ Waiting for export job to complete..."
          kubectl wait --for=condition=complete job/${JOB_NAME} \
            -n ${{ env.KSERVE_NAMESPACE }} \
            --timeout=600s || {
              echo "âŒ Export job failed or timed out"
              kubectl logs job/${JOB_NAME} -n ${{ env.KSERVE_NAMESPACE }}
              exit 1
            }
          
          echo "âœ… Model export completed"
          kubectl logs job/${JOB_NAME} -n ${{ env.KSERVE_NAMESPACE }} | tail -20

      - name: Export Summary
        run: |
          echo "## ðŸ“¦ Model Export" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Model exported to ONNX format and uploaded to Azure Blob Storage" >> $GITHUB_STEP_SUMMARY

  # ===========================================================================
  # Step 3: Deploy to Staging KServe
  # ===========================================================================
  deploy-staging:
    name: Deploy to Staging
    runs-on: ml-platform-runners
    needs: [verify-staging-model, export-model]
    if: always() && needs.verify-staging-model.result == 'success' && (needs.export-model.result == 'success' || needs.export-model.result == 'skipped')
    
    environment:
      name: staging
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/v1.28.0/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

      - name: Deploy Staging InferenceService
        run: |
          echo "ðŸš€ Deploying staging InferenceService..."
          
          # Apply YAML (uses K8s secrets, no envsubst needed)
          kubectl apply -f model-serving/inference-service/staging-isvc.yaml
          
          echo "â³ Waiting for InferenceService to be ready..."
          kubectl wait --for=condition=Ready \
            inferenceservice/spam-detector-staging \
            -n ${{ env.KSERVE_NAMESPACE }} \
            --timeout=300s || {
              echo "âš ï¸ InferenceService not ready yet, checking status..."
              kubectl get inferenceservice spam-detector-staging -n ${{ env.KSERVE_NAMESPACE }} -o yaml
            }

      - name: Restart Inference Pods
        run: |
          echo "ðŸ”„ Restarting inference pods to load new model..."
          kubectl delete pod \
            -l serving.kserve.io/inferenceservice=spam-detector-staging \
            -n ${{ env.KSERVE_NAMESPACE }} \
            --ignore-not-found=true
          
          sleep 10
          
          kubectl wait --for=condition=Ready \
            pod -l serving.kserve.io/inferenceservice=spam-detector-staging \
            -n ${{ env.KSERVE_NAMESPACE }} \
            --timeout=180s || echo "âš ï¸ Pods not ready yet"

      - name: Verify Staging Deployment
        run: |
          echo "ðŸ“Š Staging deployment status:"
          kubectl get inferenceservice spam-detector-staging -n ${{ env.KSERVE_NAMESPACE }}
          echo ""
          kubectl get pods -n ${{ env.KSERVE_NAMESPACE }} \
            -l serving.kserve.io/inferenceservice=spam-detector-staging

      - name: Staging Deployment Summary
        run: |
          echo "## ðŸš€ Staging Deployment" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Property | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Model | ${{ github.event.inputs.model_name }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Version | ${{ needs.verify-staging-model.outputs.version }} |" >> $GITHUB_STEP_SUMMARY
          echo "| InferenceService | spam-detector-staging |" >> $GITHUB_STEP_SUMMARY

  # ===========================================================================
  # Step 4: Smoke Tests
  # ===========================================================================
  smoke-tests:
    name: Smoke Tests
    runs-on: ml-platform-runners
    needs: [verify-staging-model, deploy-staging]
    
    outputs:
      test_passed: ${{ steps.smoke-test.outputs.passed }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/v1.28.0/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

      - name: Run Smoke Tests
        id: smoke-test
        run: |
          echo "ðŸ§ª Running smoke tests against staging model..."
          
          # Get predictor service URL
          PREDICTOR_SVC="spam-detector-staging-predictor.${{ env.KSERVE_NAMESPACE }}.svc.cluster.local"
          
          # Test 1: Health check via curl pod
          echo ""
          echo "Test 1: Health Check"
          HEALTH=$(kubectl run health-check-$(date +%s) \
            --image=curlimages/curl:latest \
            --restart=Never \
            --rm -i \
            --command -- curl -s "http://${PREDICTOR_SVC}/v2/health/ready" 2>/dev/null || echo "failed")
          
          if [[ "$HEALTH" == *"failed"* ]]; then
            echo "âŒ Health check failed"
            echo "passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          echo "âœ… Health check passed"
          
          # Test 2: Sample prediction
          echo ""
          echo "Test 2: Sample Prediction"
          
          TEST_INPUT='{"inputs":[{"name":"float_input","shape":[1,24],"datatype":"FP32","data":[[0.5,0.3,0.2,0.1,0.8,0.6,0.4,0.7,0.9,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.1,0.2,0.3,0.4,0.5,0.6]]}]}'
          
          PREDICTION=$(kubectl run predict-test-$(date +%s) \
            --image=curlimages/curl:latest \
            --restart=Never \
            --rm -i \
            --command -- curl -s -X POST \
            "http://${PREDICTOR_SVC}/v2/models/${{ github.event.inputs.model_name }}/infer" \
            -H "Content-Type: application/json" \
            -d "${TEST_INPUT}" 2>/dev/null || echo "prediction_failed")
          
          if [[ "$PREDICTION" == *"prediction_failed"* ]] || [[ "$PREDICTION" == *"error"* ]]; then
            echo "âŒ Prediction test failed"
            echo "Response: ${PREDICTION}"
            echo "passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          echo "âœ… Prediction test passed"
          echo "Response: ${PREDICTION}"
          
          echo "passed=true" >> $GITHUB_OUTPUT
          echo ""
          echo "âœ… All smoke tests passed!"

      - name: Smoke Test Summary
        if: always()
        run: |
          echo "## ðŸ§ª Smoke Tests" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ "${{ steps.smoke-test.outputs.passed }}" == "true" ]; then
            echo "âœ… **All smoke tests passed**" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ **Smoke tests failed**" >> $GITHUB_STEP_SUMMARY
          fi

  # ===========================================================================
  # Step 5: Verify Production Model
  # ===========================================================================
  verify-production-model:
    name: Verify Model in Production Stage
    runs-on: ml-platform-runners
    needs: [verify-staging-model, smoke-tests]
    if: github.event.inputs.deploy_production == 'true'
    
    outputs:
      version: ${{ steps.model-info.outputs.version }}
    
    steps:
      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/v1.28.0/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

      - name: Get Model in Production Stage
        id: model-info
        run: |
          echo "ðŸ” Looking for model in Production stage..."
          
          MLFLOW_URL="http://mlflow-service.${{ env.MLFLOW_NAMESPACE }}.svc.cluster.local:5000"
          
          RESPONSE=$(kubectl run mlflow-query-prod-$(date +%s) \
            --image=curlimages/curl:latest \
            --restart=Never \
            --rm -i \
            --command -- curl -s "${MLFLOW_URL}/api/2.0/mlflow/registered-models/get-latest-versions" \
            -H "Content-Type: application/json" \
            -d '{"name": "${{ github.event.inputs.model_name }}", "stages": ["Production"]}' 2>/dev/null || echo "{}")
          
          VERSION=$(echo "$RESPONSE" | grep -o '"version":"[^"]*"' | head -1 | cut -d'"' -f4)
          
          if [ -z "$VERSION" ]; then
            echo "âŒ No model found in Production stage!"
            exit 1
          fi
          
          echo "version=${VERSION}" >> $GITHUB_OUTPUT
          echo "âœ… Found model version ${VERSION} in Production stage"

      - name: Production Model Summary
        run: |
          echo "## ðŸ” Production Model Verification" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Property | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Model | ${{ github.event.inputs.model_name }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Version | ${{ steps.model-info.outputs.version }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Stage | Production |" >> $GITHUB_STEP_SUMMARY

  # ===========================================================================
  # Step 6: Deploy to Production (with approval)
  # ===========================================================================
  deploy-production:
    name: Deploy to Production
    runs-on: ml-platform-runners
    needs: [verify-staging-model, smoke-tests, verify-production-model]
    if: github.event.inputs.deploy_production == 'true'
    
    environment:
      name: production
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/v1.28.0/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

      - name: Deploy Production InferenceService
        run: |
          echo "ðŸš€ Deploying production InferenceService..."
          
          # Apply YAML (uses K8s secrets, no envsubst needed)
          kubectl apply -f model-serving/inference-service/production-isvc.yaml
          
          echo "â³ Waiting for InferenceService to be ready..."
          kubectl wait --for=condition=Ready \
            inferenceservice/spam-detector \
            -n ${{ env.KSERVE_NAMESPACE }} \
            --timeout=300s || {
              echo "âš ï¸ InferenceService not ready yet, checking status..."
              kubectl get inferenceservice spam-detector -n ${{ env.KSERVE_NAMESPACE }} -o yaml
            }

      - name: Restart Inference Pods
        run: |
          echo "ðŸ”„ Restarting inference pods to load new model..."
          kubectl delete pod \
            -l serving.kserve.io/inferenceservice=spam-detector \
            -n ${{ env.KSERVE_NAMESPACE }} \
            --ignore-not-found=true
          
          sleep 10
          
          kubectl wait --for=condition=Ready \
            pod -l serving.kserve.io/inferenceservice=spam-detector \
            -n ${{ env.KSERVE_NAMESPACE }} \
            --timeout=180s || echo "âš ï¸ Pods not ready yet"

      - name: Verify Production Deployment
        run: |
          echo "ðŸ“Š Production deployment status:"
          kubectl get inferenceservice spam-detector -n ${{ env.KSERVE_NAMESPACE }}
          echo ""
          kubectl get pods -n ${{ env.KSERVE_NAMESPACE }} \
            -l serving.kserve.io/inferenceservice=spam-detector

      - name: Production Deployment Summary
        run: |
          echo "## ðŸŽ‰ Production Deployment Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Property | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Model | ${{ github.event.inputs.model_name }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Version | ${{ needs.verify-production-model.outputs.version }} |" >> $GITHUB_STEP_SUMMARY
          echo "| InferenceService | spam-detector |" >> $GITHUB_STEP_SUMMARY
          echo "| Deployed By | @${{ github.actor }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Timestamp | $(date -u +%Y-%m-%dT%H:%M:%SZ) |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### All InferenceServices" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          kubectl get inferenceservice -n ${{ env.KSERVE_NAMESPACE }} >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

  # ===========================================================================
  # Workflow Summary
  # ===========================================================================
  summary:
    name: Deployment Summary
    runs-on: ml-platform-runners
    needs: [verify-staging-model, deploy-staging, smoke-tests]
    if: always()
    
    steps:
      - name: Generate Summary
        run: |
          echo "## ðŸ“‹ Model Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Stage | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Verify Staging Model | ${{ needs.verify-staging-model.result == 'success' && 'âœ…' || 'âŒ' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Deploy to Staging | ${{ needs.deploy-staging.result == 'success' && 'âœ…' || 'âŒ' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Smoke Tests | ${{ needs.smoke-tests.result == 'success' && 'âœ…' || 'âŒ' }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Model Details" >> $GITHUB_STEP_SUMMARY
          echo "- **Model**: ${{ github.event.inputs.model_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Version**: ${{ needs.verify-staging-model.outputs.version }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Triggered by**: @${{ github.actor }}" >> $GITHUB_STEP_SUMMARY
