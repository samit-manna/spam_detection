# KServe InferenceService - Staging Deployment
#
# Deploys the spam-detector model to staging environment using Triton runtime.
# Model is loaded from Azure Blob Storage in Triton model repository format.
#
# Prerequisites:
#   - KServe installed via Terraform
#   - azure-storage-secret exists in kserve namespace (created by Terraform)
#   - Model exported to Azure Blob (via model-export job or make export-model)
#
# Usage (no envsubst needed):
#   kubectl apply -f staging-isvc.yaml
#   make deploy-staging  # also works
---
apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: spam-detector-staging
  namespace: kserve
  labels:
    app: spam-detector
    environment: staging
    version: v1
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8080"
    serving.kserve.io/deploymentMode: "RawDeployment"
spec:
  predictor:
    minReplicas: 1
    maxReplicas: 3
    timeout: 60
    
    containers:
      - name: kserve-container
        image: nvcr.io/nvidia/tritonserver:23.05-py3
        args:
          - tritonserver
          - --model-store=/mnt/models
          - --grpc-port=9000
          - --http-port=8080
          - --allow-grpc=true
          - --allow-http=true
        ports:
          - containerPort: 8080
            protocol: TCP
        resources:
          requests:
            cpu: "500m"
            memory: "1Gi"
          limits:
            cpu: "2"
            memory: "2Gi"
        volumeMounts:
          - name: model-storage
            mountPath: /mnt/models
        readinessProbe:
          httpGet:
            path: /v2/health/ready
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        livenessProbe:
          httpGet:
            path: /v2/health/live
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 15
    
    # Init container to download model from Azure Blob Storage (Data Lake Gen2)
    # Uses azure-storage-secret (created by Terraform) - no envsubst needed
    initContainers:
      - name: storage-initializer
        image: mcr.microsoft.com/azure-cli:2.53.0
        command:
          - /bin/bash
          - -c
          - |
            set -e
            echo "Downloading model from Azure Data Lake Gen2..."
            
            echo "Account: ${AZURE_STORAGE_ACCOUNT_NAME}"
            echo "Destination: /mnt/models/spam-detector"
            
            # Clean destination
            rm -rf /mnt/models/spam-detector
            mkdir -p /mnt/models/spam-detector
            
            # List all blobs with their sizes
            echo "Listing model files..."
            az storage blob list \
              --account-name "${AZURE_STORAGE_ACCOUNT_NAME}" \
              --account-key "${AZURE_STORAGE_ACCESS_KEY}" \
              --container-name models \
              --prefix "triton-repo/spam-detector/" \
              --query "[].{name:name, size:properties.contentLength}" -o tsv > /tmp/blobs.txt
            
            cat /tmp/blobs.txt
            
            # Download each file individually (skip directory markers - 0 byte blobs)
            echo "Downloading files..."
            while read blob size; do
              # Skip directory markers (0 byte blobs or blobs ending with just a number that are 0 bytes)
              if [[ "$size" == "0" ]] || [[ -z "$size" ]]; then
                echo "Skipping directory marker (0 bytes): $blob"
                continue
              fi
              
              # Skip if it ends with / 
              if [[ "$blob" == */ ]]; then
                echo "Skipping directory: $blob"
                continue
              fi
              
              # Get the relative path (remove triton-repo/ prefix)
              rel_path="${blob#triton-repo/}"
              dest_dir="/mnt/models/$(dirname "$rel_path")"
              
              mkdir -p "$dest_dir"
              
              echo "Downloading: $blob ($size bytes) -> /mnt/models/$rel_path"
              az storage blob download \
                --account-name "${AZURE_STORAGE_ACCOUNT_NAME}" \
                --account-key "${AZURE_STORAGE_ACCESS_KEY}" \
                --container-name models \
                --name "$blob" \
                --file "/mnt/models/$rel_path" \
                --no-progress \
                -o none
            done < /tmp/blobs.txt
            
            echo "Model downloaded successfully"
            echo "Contents of /mnt/models:"
            ls -laR /mnt/models/
        env:
          - name: AZURE_STORAGE_ACCOUNT_NAME
            valueFrom:
              secretKeyRef:
                name: azure-storage-secret
                key: AZURE_STORAGE_ACCOUNT_NAME
          - name: AZURE_STORAGE_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                name: azure-storage-secret
                key: AZURE_STORAGE_ACCESS_KEY
        volumeMounts:
          - name: model-storage
            mountPath: /mnt/models
        resources:
          requests:
            cpu: "100m"
            memory: "256Mi"
          limits:
            cpu: "1"
            memory: "1Gi"
    
    volumes:
      - name: model-storage
        emptyDir: {}
---
# VirtualService for custom routing (optional)
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: spam-detector-staging-vs
  namespace: kserve
spec:
  hosts:
    - spam-detector-staging.kserve.svc.cluster.local
    - spam-detector-staging.example.com
  http:
    - match:
        - uri:
            prefix: /v2
      route:
        - destination:
            host: spam-detector-staging-predictor.kserve.svc.cluster.local
            port:
              number: 80
      timeout: 60s
      retries:
        attempts: 3
        perTryTimeout: 20s
        retryOn: "5xx,reset,connect-failure"
---
# DestinationRule for connection pool settings
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: spam-detector-staging-dr
  namespace: kserve
spec:
  host: spam-detector-staging-predictor.kserve.svc.cluster.local
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 100
        connectTimeout: 10s
      http:
        h2UpgradePolicy: UPGRADE
        http1MaxPendingRequests: 100
        http2MaxRequests: 1000
        maxRequestsPerConnection: 100
        maxRetries: 3
    loadBalancer:
      simple: ROUND_ROBIN
    outlierDetection:
      consecutive5xxErrors: 5
      interval: 30s
      baseEjectionTime: 30s
      maxEjectionPercent: 50
